{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c88d099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import os\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6beb79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6633 files belonging to 2 classes.\n",
      "Found 715 files belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 886ms/step - accuracy: 0.5806 - loss: 0.7768\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sourav Kumar\\OneDrive\\Desktop\\Atanu's Major\\.venv\\Lib\\site-packages\\keras\\src\\callbacks\\model_checkpoint.py:209: UserWarning: Can save best model only with val_accuracy available, skipping.\n",
      "  self._save_model(epoch=epoch, batch=None, logs=logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 866ms/step - accuracy: 0.7617 - loss: 0.4720\n",
      "Epoch 3/20\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 849ms/step - accuracy: 0.8958 - loss: 0.2754\n",
      "Epoch 4/20\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 851ms/step - accuracy: 0.9183 - loss: 0.2084\n",
      "Epoch 5/20\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 864ms/step - accuracy: 0.8970 - loss: 0.2566\n",
      "Epoch 6/20\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 849ms/step - accuracy: 0.9620 - loss: 0.1201\n",
      "Epoch 7/20\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 854ms/step - accuracy: 0.9611 - loss: 0.1082\n",
      "Epoch 8/20\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 854ms/step - accuracy: 0.9630 - loss: 0.1040\n",
      "Epoch 9/20\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 851ms/step - accuracy: 0.9755 - loss: 0.0675\n",
      "Epoch 10/20\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 843ms/step - accuracy: 0.9776 - loss: 0.0669\n",
      "Epoch 11/20\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 836ms/step - accuracy: 0.9774 - loss: 0.0729\n",
      "Epoch 12/20\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 846ms/step - accuracy: 0.9668 - loss: 0.0915\n",
      "Epoch 13/20\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 839ms/step - accuracy: 0.9637 - loss: 0.1070\n",
      "Epoch 14/20\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 840ms/step - accuracy: 0.9783 - loss: 0.0706\n",
      "Epoch 15/20\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 847ms/step - accuracy: 0.9860 - loss: 0.0475\n",
      "Epoch 16/20\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 835ms/step - accuracy: 0.9837 - loss: 0.0508\n",
      "Epoch 17/20\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 838ms/step - accuracy: 0.9721 - loss: 0.0818\n",
      "Epoch 18/20\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 842ms/step - accuracy: 0.9833 - loss: 0.0517\n",
      "Epoch 19/20\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 838ms/step - accuracy: 0.9879 - loss: 0.0405\n",
      "Epoch 20/20\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 842ms/step - accuracy: 0.9897 - loss: 0.0366\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 197ms/step - accuracy: 0.9937 - loss: 0.0311\n",
      "Test accuracy: 0.9958\n"
     ]
    }
   ],
   "source": [
    "# Define paths to your dataset folders\n",
    "train_dir = r\"C:\\Users\\Sourav Kumar\\OneDrive\\Desktop\\Atanu's Major\\data1\\casting_data\\casting_data\\train\" # Update with your train images folder path\n",
    "#valid_dir = r\"C:\\Users\\Sourav Kumar\\OneDrive\\Desktop\\Atanu's Major\\Casting detection.v10-good_version.yolov11\\valid\\images\" # Update with your validation images folder path\n",
    "test_dir = r\"C:\\Users\\Sourav Kumar\\OneDrive\\Desktop\\Atanu's Major\\data1\\casting_data\\casting_data\\test\"  # Update with your test images folder path\n",
    "\n",
    "# Image parameters\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 1  # Binary classification (defective vs non_defective)\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "'''valid_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    valid_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")'''\n",
    "\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "# Build CNN model\n",
    "def create_cnn_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "        data_augmentation,\n",
    "        layers.Rescaling(1./255),  # Normalize pixel values\n",
    "        layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(NUM_CLASSES, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = create_cnn_model()\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Define checkpoint callback\n",
    "checkpoint_path = \"checkpoints/cp-{epoch:04d}.weights.h5\"\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path,\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "EPOCHS = 20\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    #validation_data=valid_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Evaluate on test dataset\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Save model in TensorFlow SavedModel format\n",
    "model.save('defect_classification_model.keras')\n",
    "\n",
    "# Optional: Load the best checkpoint for further use\n",
    "# model.load_weights('checkpoints/cp-best.weights.h5')  # Replace with the best checkpoint file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
